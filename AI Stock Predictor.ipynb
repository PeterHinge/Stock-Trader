{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_NAME = 'BTC-USD'\n",
    "DATA_VALUES = ['time', 'low', 'high', 'open', 'close', 'volume']\n",
    "VALUES_TO_LEARN_FROM = ['close', 'volume']  # please include 'close' as 0th index value\n",
    "DATA_REVERSED = False\n",
    "\n",
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_SIZE = 0.05\n",
    "MODEL_NAME = f\"{DATA_FILE_NAME}-{SEQ_LEN}-{FUTURE_PERIOD_PREDICT}-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targeting(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def preprocessing_df(df):\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "\n",
    "    lower = min(len(buys), len(sells))\n",
    "\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time          low         high         open        close    volume\n",
      "0  1528968660  6489.549805  6489.560059  6489.560059  6489.549805  0.587100\n",
      "1  1528968720  6487.370117  6489.560059  6489.549805  6487.379883  7.706374\n",
      "2  1528968780  6479.410156  6487.370117  6487.370117  6479.410156  3.088252\n",
      "3  1528968840  6479.410156  6479.419922  6479.419922  6479.410156  1.404100\n",
      "4  1528968900  6475.930176  6479.979980  6479.410156  6479.979980  0.753000\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data = pd.read_csv(f'data/{DATA_FILE_NAME}.csv', names=DATA_VALUES)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close    volume\n",
      "0  6489.549805  0.587100\n",
      "1  6487.379883  7.706374\n",
      "2  6479.410156  3.088252\n",
      "3  6479.410156  1.404100\n",
      "4  6479.979980  0.753000\n"
     ]
    }
   ],
   "source": [
    "df = data[VALUES_TO_LEARN_FROM].copy()\n",
    "if DATA_REVERSED:\n",
    "    df = df[::-1]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close    volume  target\n",
      "0  6489.549805  0.587100       0\n",
      "1  6487.379883  7.706374       0\n",
      "2  6479.410156  3.088252       1\n",
      "3  6479.410156  1.404100       0\n",
      "4  6479.979980  0.753000       1\n",
      "5  6480.000000  1.490900       0\n",
      "6  6477.220215  2.731950       1\n",
      "7  6480.000000  2.174240       0\n",
      "8  6479.990234  0.903100       0\n",
      "9  6478.660156  3.258786       1\n"
     ]
    }
   ],
   "source": [
    "df['future'] = df[VALUES_TO_LEARN_FROM[0]].shift(-FUTURE_PERIOD_PREDICT)\n",
    "df['target'] = list(map(targeting, df[VALUES_TO_LEARN_FROM[0]], df['future']))\n",
    "df = df.drop('future', 1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 83162, Validation data: 4484\n",
      "Dont buys: 41581, Buys: 41581\n",
      "VALIDATION - Dont buys: 2242, Buys: 2242\n"
     ]
    }
   ],
   "source": [
    "train_df = df[(df.index <= int(len(df.index) * (1 - VALIDATION_SIZE)))].copy()\n",
    "validation_df = df[(df.index > int(len(df.index) * (1 - VALIDATION_SIZE)))].copy()\n",
    "\n",
    "train_x, train_y = preprocessing_df(train_df)\n",
    "validation_x, validation_y = preprocessing_df(validation_df)\n",
    "\n",
    "print(\"Training data: {}, Validation data: {}\".format(len(train_x), len(validation_x)))\n",
    "print(\"Dont buys: {}, Buys: {}\".format(train_y.count(0), train_y.count(1)))\n",
    "print(\"VALIDATION - Dont buys: {}, Buys: {}\".format(validation_y.count(0), validation_y.count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have tensorflow-gpu, you can change the CuDNNLSTM cell-layers to regular LSTM cell-layers (slower)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(MODEL_NAME))\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 83162 samples, validate on 4484 samples\n",
      "Epoch 1/15\n",
      "83162/83162 [==============================] - 43s 512us/step - loss: 0.7088 - acc: 0.5186 - val_loss: 0.6896 - val_acc: 0.51852 -\n",
      "Epoch 2/15\n",
      "83162/83162 [==============================] - 41s 497us/step - loss: 0.6890 - acc: 0.5352 - val_loss: 0.6886 - val_acc: 0.5404\n",
      "Epoch 3/15\n",
      "83162/83162 [==============================] - 41s 488us/step - loss: 0.6854 - acc: 0.5533 - val_loss: 0.6814 - val_acc: 0.5598\n",
      "Epoch 4/15\n",
      "83162/83162 [==============================] - 41s 493us/step - loss: 0.6830 - acc: 0.5598 - val_loss: 0.6937 - val_acc: 0.5450\n",
      "Epoch 5/15\n",
      "83162/83162 [==============================] - 41s 499us/step - loss: 0.6822 - acc: 0.5639 - val_loss: 0.6785 - val_acc: 0.5674\n",
      "Epoch 6/15\n",
      "83162/83162 [==============================] - 41s 495us/step - loss: 0.6812 - acc: 0.5669 - val_loss: 0.6797 - val_acc: 0.5665\n",
      "Epoch 7/15\n",
      "83162/83162 [==============================] - 41s 495us/step - loss: 0.6803 - acc: 0.5693 - val_loss: 0.6822 - val_acc: 0.5631\n",
      "Epoch 8/15\n",
      "83162/83162 [==============================] - 41s 496us/step - loss: 0.6787 - acc: 0.5741 - val_loss: 0.6776 - val_acc: 0.5709\n",
      "Epoch 9/15\n",
      "83162/83162 [==============================] - 41s 495us/step - loss: 0.6778 - acc: 0.5732 - val_loss: 0.6785 - val_acc: 0.5662\n",
      "Epoch 10/15\n",
      "83162/83162 [==============================] - 41s 497us/step - loss: 0.6771 - acc: 0.5753 - val_loss: 0.6766 - val_acc: 0.5792\n",
      "Epoch 11/15\n",
      "83162/83162 [==============================] - 42s 502us/step - loss: 0.6750 - acc: 0.5786 - val_loss: 0.6807 - val_acc: 0.5584\n",
      "Epoch 12/15\n",
      "83162/83162 [==============================] - 42s 508us/step - loss: 0.6727 - acc: 0.5846 - val_loss: 0.6815 - val_acc: 0.5613\n",
      "Epoch 13/15\n",
      "83162/83162 [==============================] - 43s 517us/step - loss: 0.6703 - acc: 0.5881 - val_loss: 0.6788 - val_acc: 0.5642\n",
      "Epoch 14/15\n",
      "83162/83162 [==============================] - 42s 510us/step - loss: 0.6673 - acc: 0.5936 - val_loss: 0.6781 - val_acc: 0.5700\n",
      "Epoch 15/15\n",
      "83162/83162 [==============================] - 42s 508us/step - loss: 0.6614 - acc: 0.6015 - val_loss: 0.6856 - val_acc: 0.5638\n",
      "Test loss: 0.685625539678851\n",
      "Test accuracy: 0.5637823371989296\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"models/{}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
