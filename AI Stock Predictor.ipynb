{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_NAME = 'BTC-USD'\n",
    "DATA_VALUES = ['time', 'low', 'high', 'open', 'close', 'volume']\n",
    "VALUES_TO_LEARN_FROM = ['close', 'volume']  # please include 'close' as 0th index value\n",
    "DATA_REVERSED = False\n",
    "\n",
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_SIZE = 0.05\n",
    "MODEL_NAME = f\"{DATA_FILE_NAME}-{SEQ_LEN}-{FUTURE_PERIOD_PREDICT}-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targeting(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def preprocessing_df(df):\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "\n",
    "    lower = min(len(buys), len(sells))\n",
    "\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time          low         high         open        close    volume\n",
      "0  1528968660  6489.549805  6489.560059  6489.560059  6489.549805  0.587100\n",
      "1  1528968720  6487.370117  6489.560059  6489.549805  6487.379883  7.706374\n",
      "2  1528968780  6479.410156  6487.370117  6487.370117  6479.410156  3.088252\n",
      "3  1528968840  6479.410156  6479.419922  6479.419922  6479.410156  1.404100\n",
      "4  1528968900  6475.930176  6479.979980  6479.410156  6479.979980  0.753000\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data = pd.read_csv(f'data/{DATA_FILE_NAME}.csv', names=DATA_VALUES)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close    volume\n",
      "0  6489.549805  0.587100\n",
      "1  6487.379883  7.706374\n",
      "2  6479.410156  3.088252\n",
      "3  6479.410156  1.404100\n",
      "4  6479.979980  0.753000\n"
     ]
    }
   ],
   "source": [
    "df = data[VALUES_TO_LEARN_FROM].copy()\n",
    "if DATA_REVERSED:\n",
    "    df = df[::-1]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         close    volume  target\n",
      "0  6489.549805  0.587100       0\n",
      "1  6487.379883  7.706374       0\n",
      "2  6479.410156  3.088252       1\n",
      "3  6479.410156  1.404100       0\n",
      "4  6479.979980  0.753000       1\n",
      "5  6480.000000  1.490900       0\n",
      "6  6477.220215  2.731950       1\n",
      "7  6480.000000  2.174240       0\n",
      "8  6479.990234  0.903100       0\n",
      "9  6478.660156  3.258786       1\n"
     ]
    }
   ],
   "source": [
    "df['future'] = df[VALUES_TO_LEARN_FROM[0]].shift(-FUTURE_PERIOD_PREDICT)\n",
    "df['target'] = list(map(targeting, df[VALUES_TO_LEARN_FROM[0]], df['future']))\n",
    "df = df.drop('future', 1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 83162, Validation data: 4484\n",
      "Dont buys: 41581, Buys: 41581\n",
      "VALIDATION - Dont buys: 2242, Buys: 2242\n"
     ]
    }
   ],
   "source": [
    "train_df = df[(df.index <= int(len(df.index) * (1 - VALIDATION_SIZE)))].copy()\n",
    "validation_df = df[(df.index > int(len(df.index) * (1 - VALIDATION_SIZE)))].copy()\n",
    "\n",
    "train_x, train_y = preprocessing_df(train_df)\n",
    "validation_x, validation_y = preprocessing_df(validation_df)\n",
    "\n",
    "print(\"Training data: {}, Validation data: {}\".format(len(train_x), len(validation_x)))\n",
    "print(\"Dont buys: {}, Buys: {}\".format(train_y.count(0), train_y.count(1)))\n",
    "print(\"VALIDATION - Dont buys: {}, Buys: {}\".format(validation_y.count(0), validation_y.count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have tensorflow-gpu, you can change the CuDNNLSTM cell-layers to regular LSTM cell-layers (slower)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(MODEL_NAME))\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 83162 samples, validate on 4484 samples\n",
      "Epoch 1/15\n",
      "83162/83162 [==============================] - 41s 489us/step - loss: 0.6248 - acc: 0.6216 - val_loss: 0.6927 - val_acc: 0.5172\n",
      "Epoch 2/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.6181 - acc: 0.6416 - val_loss: 0.7999 - val_acc: 0.5368\n",
      "Epoch 3/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5794 - acc: 0.6946 - val_loss: 0.7963 - val_acc: 0.5183\n",
      "Epoch 4/15\n",
      "83162/83162 [==============================] - 41s 489us/step - loss: 0.5679 - acc: 0.7030 - val_loss: 0.7866 - val_acc: 0.5323\n",
      "Epoch 5/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5577 - acc: 0.7100 - val_loss: 0.8029 - val_acc: 0.5348\n",
      "Epoch 6/15\n",
      "83162/83162 [==============================] - 41s 491us/step - loss: 0.5514 - acc: 0.7170 - val_loss: 0.8132 - val_acc: 0.5435\n",
      "Epoch 7/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5442 - acc: 0.7233 - val_loss: 0.7764 - val_acc: 0.5283\n",
      "Epoch 8/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5393 - acc: 0.7248 - val_loss: 0.8339 - val_acc: 0.5323\n",
      "Epoch 9/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5333 - acc: 0.7315 - val_loss: 0.8955 - val_acc: 0.5236\n",
      "Epoch 10/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5311 - acc: 0.7326 - val_loss: 0.8266 - val_acc: 0.5268\n",
      "Epoch 11/15\n",
      "83162/83162 [==============================] - 41s 491us/step - loss: 0.5224 - acc: 0.7381 - val_loss: 0.9092 - val_acc: 0.5364\n",
      "Epoch 12/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5188 - acc: 0.7421 - val_loss: 0.8521 - val_acc: 0.5279\n",
      "Epoch 13/15\n",
      "83162/83162 [==============================] - 41s 490us/step - loss: 0.5159 - acc: 0.7446 - val_loss: 0.8781 - val_acc: 0.5270\n",
      "Epoch 14/15\n",
      "83162/83162 [==============================] - 41s 491us/step - loss: 0.5114 - acc: 0.7465 - val_loss: 0.8654 - val_acc: 0.5299\n",
      "Epoch 15/15\n",
      "83162/83162 [==============================] - 41s 491us/step - loss: 0.5090 - acc: 0.7481 - val_loss: 0.8654 - val_acc: 0.5312\n",
      "Test loss: 0.8653643688487751\n",
      "Test accuracy: 0.5312221231043711\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save(\"models/{}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
